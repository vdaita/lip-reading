{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [08:29<00:00,  8.49s/it]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "word_data_file = open(\"word_data.json\", \"r\")\n",
    "word_data = json.loads(word_data_file.read())\n",
    "word_data_file.close()\n",
    "\n",
    "all_words = []\n",
    "for segment in word_data[\"output\"][\"segments\"]:\n",
    "    all_words.extend(segment[\"words\"])\n",
    "\n",
    "word_list = []\n",
    "\n",
    "for word in all_words:\n",
    "    word_list.append(word[\"word\"])\n",
    "\n",
    "phonemes_set = set()\n",
    "phonemes_map = {}\n",
    "\n",
    "def split_list_into_k_parts(lst, k):\n",
    "    return [lst[i * len(lst) // k: (i + 1) * len(lst) // k] for i in range(k)]\n",
    "\n",
    "words_lists = split_list_into_k_parts(word_list, 60)\n",
    "\n",
    "for wl in tqdm(words_lists):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Given this list of words, output a JSON file where each word is mapped to a list of phonemes. This speech was delivered by President Barack Obama. Don't format the phonemes with slashes - just the representative characters themselves. Don't include punctuation or use any special symbols: the symbols used should be within the 44 standard symbols used to describe English pronunciation only. \"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": json.dumps(wl)\n",
    "            }\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    content = json.loads(response.choices[0].message.content)\n",
    "    phonemes_map.update(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemes_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n",
      "meant\n",
      "that\n",
      "there\n",
      "was\n",
      "less\n",
      "money\n",
      "coming\n",
      "in\n",
      "and\n",
      "it\n",
      "required\n",
      "us\n",
      "to\n",
      "spend\n",
      "even\n",
      "more\n",
      "on\n",
      "tax\n",
      "cuts\n",
      "for\n",
      "middleclass\n",
      "families\n",
      "to\n",
      "spur\n",
      "the\n",
      "economy\n",
      "on\n",
      "unemployment\n",
      "insurance\n",
      "on\n",
      "aid\n",
      "to\n",
      "states\n",
      "so\n",
      "we\n",
      "could\n",
      "prevent\n",
      "more\n",
      "teachers\n",
      "and\n",
      "firefighters\n",
      "and\n",
      "police\n",
      "officers\n",
      "from\n",
      "being\n",
      "laid\n",
      "off\n",
      "these\n",
      "emergency\n",
      "steps\n",
      "also\n",
      "added\n",
      "to\n",
      "the\n",
      "deficit\n",
      "now\n",
      "every\n",
      "family\n",
      "knows\n",
      "a\n",
      "little\n",
      "credit\n",
      "card\n",
      "debt\n",
      "is\n",
      "manageable\n",
      "but\n",
      "if\n",
      "we\n",
      "stay\n",
      "on\n",
      "the\n",
      "current\n",
      "path\n",
      "our\n",
      "growing\n",
      "debt\n",
      "could\n",
      "cost\n",
      "us\n",
      "jobs\n",
      "and\n",
      "do\n",
      "serious\n",
      "damage\n",
      "to\n",
      "the\n",
      "economy\n",
      "more\n",
      "of\n",
      "our\n",
      "tax\n",
      "dollars\n",
      "will\n",
      "go\n",
      "toward\n",
      "paying\n",
      "off\n",
      "the\n",
      "interest\n",
      "on\n",
      "our\n",
      "loans\n",
      "businesses\n",
      "will\n",
      "be\n",
      "less\n",
      "likely\n",
      "to\n",
      "open\n",
      "up\n",
      "shop\n",
      "and\n",
      "hire\n",
      "workers\n",
      "in\n",
      "a\n",
      "country\n",
      "that\n",
      "cant\n",
      "balance\n",
      "its\n",
      "books\n",
      "interest\n",
      "rates\n",
      "could\n",
      "climb\n",
      "for\n",
      "everyone\n",
      "who\n",
      "borrows\n",
      "money\n",
      "the\n",
      "homeowner\n",
      "with\n",
      "a\n",
      "mortgage\n",
      "the\n",
      "student\n",
      "with\n",
      "a\n",
      "college\n",
      "loan\n",
      "the\n",
      "corner\n",
      "store\n",
      "that\n",
      "wants\n",
      "to\n",
      "expand\n",
      "and\n",
      "we\n",
      "wont\n",
      "have\n",
      "enough\n",
      "money\n",
      "to\n",
      "make\n",
      "jobcreating\n",
      "investments\n",
      "in\n",
      "things\n",
      "like\n",
      "education\n",
      "and\n",
      "infrastructure\n",
      "or\n",
      "pay\n",
      "for\n",
      "vital\n",
      "programs\n",
      "like\n",
      "medicare\n",
      "and\n",
      "medicaid\n",
      "because\n",
      "neither\n",
      "party\n",
      "is\n",
      "blameless\n",
      "for\n",
      "the\n",
      "decisions\n",
      "that\n",
      "led\n",
      "to\n",
      "this\n",
      "problem\n",
      "both\n",
      "parties\n",
      "have\n",
      "a\n",
      "responsibility\n",
      "to\n",
      "solve\n",
      "it\n",
      "and\n",
      "over\n",
      "the\n",
      "last\n",
      "several\n",
      "months\n",
      "thats\n",
      "what\n",
      "weve\n",
      "been\n",
      "trying\n",
      "to\n",
      "do\n",
      "i\n",
      "wont\n",
      "bore\n",
      "you\n",
      "with\n",
      "the\n",
      "details\n",
      "of\n",
      "every\n",
      "plan\n",
      "or\n",
      "proposal\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'proposal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(w)\n\u001b[0;32m---> 21\u001b[0m     all_words[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphonemes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnew_key_phonemes_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mw\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     22\u001b[0m     phonemes_set\u001b[38;5;241m.\u001b[39mupdate(new_key_phonemes_map[w])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(phonemes_set))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'proposal'"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "all_words = []\n",
    "for segment in word_data[\"output\"][\"segments\"]:\n",
    "    all_words.extend(segment[\"words\"])\n",
    "\n",
    "new_key_phonemes_map = {}\n",
    "for key in phonemes_map:\n",
    "    k = key.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    k = k.replace(\"-\", \"\")\n",
    "    k = k.replace(\"–\", \"\")\n",
    "    new_key_phonemes_map[k] = phonemes_map[key]\n",
    "\n",
    "for i in range(len(word_list)):\n",
    "    w = all_words[i][\"word\"].translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    w = w.replace(\"-\", \"\")\n",
    "    w = w.replace(\"–\", \"\")\n",
    "    if len(w) == 0:\n",
    "        continue\n",
    "    print(w)\n",
    "    all_words[i][\"phonemes\"] = new_key_phonemes_map[w]\n",
    "    phonemes_set.update(new_key_phonemes_map[w])\n",
    "\n",
    "print(list(phonemes_set))\n",
    "print(len(list(phonemes_set)))\n",
    "\n",
    "output_file = open(\"phoneme-data.json\", \"w+\")\n",
    "output_file.write(json.dumps(all_words, indent=4))\n",
    "output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
